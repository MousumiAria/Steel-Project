{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"C:\\Users\\masud\\OneDrive - students.boku.ac.at\\Becode\\Project\\SteelComp\\CoilData.csv\"\n",
    "data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_id = []\n",
    "for id in data.coil:\n",
    "    all_id.append(id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57094"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(all_id)\n",
    "#all_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import OS module\n",
    "import os\n",
    " \n",
    "# Get the list of all files and directories\n",
    "path = r\"C:\\Users\\masud\\Downloads\\SignalExport\"\n",
    "dir_list = os.listdir(path)\n",
    " \n",
    "# prints all files\n",
    "#print(dir_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113540"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dir_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanfile = []\n",
    "for id in all_id:\n",
    "    #print (id)\n",
    "  x = (str(id) +\"B4.csv\") \n",
    "  y = (str(id) +\"B5.csv\") \n",
    "  #print(y)\n",
    "  if x in dir_list and y in dir_list:\n",
    "    cleanfile.append(id)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorting_file(path):\n",
    "   \n",
    "    for line in open(path, 'r'):\n",
    "        if line.endswith(\"Values;\"):\n",
    "            return False\n",
    "        if line.startswith(\"No\"):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "index = 0\n",
    "for few in cleanfile_dp['coilno']:\n",
    "    x = (str(few) +\"B4.csv\") \n",
    "    y = (str(few) +\"B5.csv\") \n",
    "    pathB4 = r\"C:\\\\Users\\\\masud\\Downloads\\\\SignalExport\\\\\" + x\n",
    "    pathB5= r\"C:\\\\Users\\\\masud\\Downloads\\\\SignalExport\\\\\" + y\n",
    "\n",
    "    if sorting_file(pathB4):\n",
    "        if sorting_file(pathB5):\n",
    "            cleanfile_dp.at[index,'clean']=1\n",
    "            \n",
    "    else:\n",
    "        pass\n",
    "    index +=1\n",
    "            \n",
    "cleanfile_dp.to_csv(\"finalCleanData.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56743"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('finalCleanData.csv')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coil(coil_number,stage):\n",
    "    # load one csv for the coil at the stage B4 or B5\n",
    "    df = pd.read_csv(f'SignalExport/{coil_number}B{stage}.csv')\n",
    "    # Turn it into the list and split it by semicolon\n",
    "    df= list(df.columns)[0].split(\";\")\n",
    "    # Finding index for the length and width\n",
    "    li=df.index(\"Lengthpoints:\") \n",
    "    wi=df.index(\"Values\")\n",
    "    # Slicing the dataframe into 4 lists \n",
    "    coil_num =df[0]\n",
    "    coil_stage = df[1]\n",
    "    length=df[li+1:wi]   \n",
    "    width=df[wi+1:-1]\n",
    "    # Checking the number of observations in the lists\n",
    "    #print(f\"Number of observations:{len(length),len(width)}\")\n",
    "    # Turning length and width measurements from a string into a float \n",
    "    length = [float(i) for i in length]\n",
    "    width = [float(i) for i in width]\n",
    "    #Duplicate the coil number for the number of observations in the length \n",
    "    mult_coil_values= [coil_num for i in range(len(length))]\n",
    "    mult_coil_stage_values = [coil_stage for i in range(len(length))]\n",
    "    # Create an empty dataframe \n",
    "    my_df = pd.DataFrame()\n",
    "    # Turn in the lists into the series  \n",
    "    mult_coil_values = pd.Series(mult_coil_values)\n",
    "    coil_stage_values= pd.Series(mult_coil_stage_values)\n",
    "    length_values = pd.Series(length)\n",
    "    width_values = pd.Series(width)\n",
    "    # Create columns and fill them with the series \n",
    "    my_df['coil_number'] = mult_coil_values\n",
    "    my_df['coil_stage'] = mult_coil_stage_values\n",
    "    my_df['length'] = length_values\n",
    "    my_df['width'] = width_values\n",
    "    # Drop the zeros\n",
    "    my_df = my_df[(my_df != 0).all(1)]\n",
    "    #Looking at only 140-170 m length\n",
    "    new_df= my_df.loc[(my_df['length'] >= 140) & (my_df['length'] <= 170)]\n",
    "    #\n",
    "    new_df[\"length_m\"] = new_df[\"length\"].astype(int)\n",
    "    # Checking the shape new_df_B4.shape \n",
    "    #print(f\"The shape of the sliced dataset is {new_df.shape}\")\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55769"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_withoutError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_withoutError.to_csv(\"coil_to_used.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c0ec2fa64e559bcf1e26b72294f8d7964640e4d45d429ea8cc58c0ee1727d470"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
